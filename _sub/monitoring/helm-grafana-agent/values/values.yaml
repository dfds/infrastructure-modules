cluster:
  name: ${cluster_name}
alloy:
  alloy:
%{ if storage_enabled ~}
    clustering:
      enabled: true
    storagePath: /var/lib/agent
    mounts:
      extra:
        - mountPath: /var/lib/agent
          name: agent-wal
%{ endif ~}
    resources:
      requests:
        memory: ${agent_resource_memory_request}
      limits:
        memory: ${agent_resource_memory_limit}
%{ if length(tolerations) > 0 || length(affinity) > 0 || storage_enabled ~}
  controller:
%{ endif ~}
%{ if length(tolerations) > 0 ~}
    tolerations:
%{ for t in tolerations ~}
    - key: ${t.key}
      operator: ${t.operator}
%{ if t.value != null ~}
      value: ${t.value}
%{ endif ~}
      effect: ${t.effect}
%{ endfor ~}
%{ endif ~}
%{ if length(affinity) > 0 ~}
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          preference:
            matchExpressions:
%{ for a in affinity ~}
            - key: ${a.key}
              operator: ${a.operator}
              values:
%{ for v in a.values ~}
              - ${ v }
%{ endfor ~}
%{ endfor ~}
%{ endif ~}
%{ if storage_enabled ~}
    replicas: ${agent_replicas}
    volumeClaimTemplates:
      - metadata:
          name: agent-wal
        spec:
          accessModes: [ "ReadWriteOnce" ]
          storageClassName: ${storage_class}
          resources:
            requests:
              storage: ${storage_size}
%{ endif ~}
externalServices:
  prometheus:
    host: ${prometheus_url}

    ## Remove this block  when PR is ready
    authMode: none
    writeEndpoint: /api/v1/push
    queryEndpoint: /api/v1/query
    ####################################
  loki:
    host: ${loki_url}
    ## Remove this block  when PR is ready
    authMode: none
    ####################################

# externalServices: # TODO: re-activate this when PR is ready
#   prometheus:
#     host: ${prometheus_url}
#     basicAuth:
#       username: "${prometheus_username}"
#       password: ${api_token}
#   loki:
#     host: ${loki_url}
#     basicAuth:
#       username: ${loki_username}
#       password: ${api_token}
#   tempo:
#     host: ${tempo_url}
#     basicAuth:
#       username: ${tempo_username}
#       password: ${api_token}
opencost:
  enabled: ${open_cost_enabled}
  opencost:
    exporter:
      defaultClusterId: ${cluster_name}
    prometheus:
      external:
        url: ${prometheus_url}/api/prom
traces:
  enabled: ${traces_enabled}
%{ if enable_side_by_side ~}
metrics:
  node-exporter: # activating this causes duplicates => integrations/node_exporter
    enabled: false
    # labelMatchers:
    #   app.kubernetes.io/name: prometheus-node-exporter
    service:
      isTLS: false
  kube-state-metrics:
    # -- Scrape cluster object metrics from Kube State Metrics
    enabled: false

  # Container metrics from cAdvisor
  cadvisor:
    # -- Scrape container metrics from cAdvisor
    enabled: false


prometheus-operator-crds:
  enabled: false
# kube-state-metrics:
#   enabled: false
%{ endif ~}

prometheus-node-exporter:
  enabled: true
  podLabels:
    ## Add the 'node-exporter' label to be used by serviceMonitor to match standard common usage in rules and grafana dashboards
    ##
    jobLabel: node-exporter
  resources:
    requests:
      cpu: 20m
      memory: 50Mi
  priorityClassName: ${prometheus_node_exporter_priorityclass}
  prometheus:
    monitor: # ServiceMonitor
      enabled: true
      jobLabel: jobLabel # it will set the jobLabel in the ServiceMonitor spec to look for label value. If not set it will use app.kubernetes.io/name instead
      additionalLabels: {
        release: monitoring
      }

kube-state-metrics:
  enabled: true
  customLabels:
    jobLabel: kube-state-metrics
  resources:
    requests:
      cpu: 20m
      memory: 100Mi
  priorityClassName: ${kube_state_metrics_priorityclass}
  # releaseLabel: true
  prometheus:
    monitor:
      enabled: true
      jobLabel: jobLabel
      additionalLabels: {
        release: monitoring
      }
%{ if length(tolerations) > 0 ~}
  tolerations:
%{ for t in tolerations ~}
  - key: ${t.key}
    operator: ${t.operator}
%{ if t.value != null ~}
    value: ${t.value}
%{ endif ~}
    effect: ${t.effect}
%{ endfor ~}
%{ endif ~}
%{ if length(affinity) > 0 ~}
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
%{ for a in affinity ~}
          - key: ${a.key}
            operator: ${a.operator}
            values:
%{ for v in a.values ~}
            - ${ v }
%{ endfor ~}
%{ endfor ~}
%{ endif ~}

extraObjects:
- apiVersion: monitoring.coreos.com/v1 # TODO: give a different name to highlight that is from kube-prometheus-stack (legacy) and also enable the cAdvisor job from this chart
  kind: ServiceMonitor
  metadata:
    labels:
      app: kube-prometheus-stack-kubelet
      release: monitoring
    name: monitoring-kube-prometheus-kubelet
    namespace: grafana-agent
  spec:
    attachMetadata:
      node: false
    endpoints:
    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      honorLabels: true
      honorTimestamps: true
      port: https-metrics
      relabelings:
      - action: replace
        sourceLabels:
        - __metrics_path__
        targetLabel: metrics_path
      scheme: https
      tlsConfig:
        caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecureSkipVerify: true
    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      honorLabels: true
      honorTimestamps: true
      metricRelabelings:
      - action: labeldrop
        regex: id
      - action: labeldrop
        regex: name
      path: /metrics/cadvisor
      port: https-metrics
      relabelings:
      - action: replace
        sourceLabels:
        - __metrics_path__
        targetLabel: metrics_path
      scheme: https
      tlsConfig:
        caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecureSkipVerify: true
    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      honorLabels: true
      honorTimestamps: true
      path: /metrics/probes
      port: https-metrics
      relabelings:
      - action: replace
        sourceLabels:
        - __metrics_path__
        targetLabel: metrics_path
      scheme: https
      tlsConfig:
        caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecureSkipVerify: true
    jobLabel: k8s-app
    namespaceSelector:
      matchNames:
      - kube-system
    selector:
      matchLabels:
        app.kubernetes.io/name: kubelet
        k8s-app: kubelet
- apiVersion: monitoring.coreos.com/v1
  kind: ServiceMonitor
  metadata:
    name: kube-prometheus-stack-coredns
    namespace: grafana-agent
    labels:
      app: kube-prometheus-stack-coredns
      app.kubernetes.io/instance: kube-prometheus-stack
      release: monitoring # was missing
  spec:
    jobLabel: jobLabel
    selector:
      matchLabels:
        app: kube-prometheus-stack-coredns
        release: monitoring
    namespaceSelector:
      matchNames:
        - kube-system
    endpoints:
    - port: http-metrics
      bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
- apiVersion: v1
  kind: Service
  metadata:
    name: kube-prometheus-stack-coredns
    labels:
      app: kube-prometheus-stack-coredns
      jobLabel: coredns # this is used for the exporter
      app.kubernetes.io/instance: kube-prometheus-stack
      release: monitoring
    namespace: kube-system
  spec:
    clusterIP: None
    ports:
      - name: http-metrics
        port: 9153
        protocol: TCP
        targetPort: 9153
    selector:
      k8s-app: kube-dns

- apiVersion: monitoring.coreos.com/v1
  kind: ServiceMonitor
  metadata:
    name: kube-prometheus-stack-apiserver
    namespace: grafana-agent
    labels:
      app: kube-prometheus-stack-apiserver
      app.kubernetes.io/instance: kube-prometheus-stack
      release: monitoring
  spec:
    endpoints:
    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      port: https
      scheme: https
      metricRelabelings:
        - action: drop
          regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)
          sourceLabels:
          - __name__
          - le
      tlsConfig:
        caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        serverName: kubernetes
        insecureSkipVerify: false
    jobLabel: component
    namespaceSelector:
      matchNames:
      - default
    selector:
      matchLabels:
        component: apiserver
        provider: kubernetes
